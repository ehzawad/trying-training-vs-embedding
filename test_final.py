#!/usr/bin/env python3
"""
Final Test Script for Bengali Legal Embeddings
Tests the trained model against out-of-scope queries and training data
"""

import numpy as np
from sentence_transformers import SentenceTransformer, util
from sklearn.metrics.pairwise import cosine_similarity
from pathlib import Path
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_final_model():
    """
    Comprehensive test of the final trained model
    """
    
    model_path = "models/namjari-final/final"
    
    try:
        logger.info(f"Loading final model: {model_path}")
        trained_model = SentenceTransformer(model_path)
    except Exception as e:
        logger.error(f"Model not found: {e}")
        logger.info("Please run train_final.py first")
        return None
    
    # Load base model for comparison
    base_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    # Test 1: In-scope Namjari queries
    namjari_queries = [
        "‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø‡¶∞ ‡¶´‡¶ø ‡¶ï‡¶§ ‡¶ü‡¶æ‡¶ï‡¶æ?", 
        "‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶¶‡¶≤‡¶ø‡¶≤ ‡¶≤‡¶æ‡¶ó‡ßá?",
        "‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø ‡¶Ü‡¶¨‡ßá‡¶¶‡¶® ‡¶ï‡ßã‡¶•‡¶æ‡¶Ø‡¶º ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶Ø‡¶º?",
        "‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø‡¶∞ ‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶ü‡¶æ‡¶∏ ‡¶ö‡ßá‡¶ï ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á‡•§"
    ]
    
    # Test 2: Out-of-scope queries (your critical test data)
    out_of_scope_queries = [
        "‡¶ú‡¶Æ‡¶ø ‡¶¶‡¶ñ‡¶≤‡ßá‡¶∞ ‡¶ï‡¶ø‡¶≠‡¶æ‡¶¨‡ßá ‡¶™‡ßá‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø?",
        "‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶π‡¶æ‡¶∞‡¶ø‡¶Ø‡¶º‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶¨‡¶á ‡¶™‡ßá‡¶§‡ßá ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶π‡¶ú‡ßç‡¶¨ ‡¶ï‡¶∞‡¶§‡ßá ‡¶ö‡¶æ‡¶á, ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶Ö‡¶®‡¶≤‡¶æ‡¶á‡¶®‡ßá ‡¶ì‡¶Æ‡¶∞‡¶æ‡¶π‡ßç‚Äå ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶Æ‡¶ø‡¶â‡¶ü ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶≤‡ßá ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶Ü‡¶Æ‡¶ø ‡¶ì‡¶Æ‡¶∞‡¶æ‡¶π‡ßç‚Äå ‡¶ï‡¶∞‡¶¨‡ßã ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶ï‡ßã‡¶Æ‡ßç‡¶™‡¶æ‡¶®‡¶ø‡¶§‡ßá ‡¶Ü‡¶¨‡ßá‡¶¶‡¶® ‡¶ï‡¶ø ‡¶®‡¶ø‡¶ú‡ßá ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø‡•§",
        "‡¶ú‡¶Æ‡¶ø ‡¶¶‡¶ñ‡¶≤ ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶≠‡ßÇ‡¶Æ‡¶ø ‡¶Ö‡¶´‡¶ø‡¶∏‡ßá ‡¶Ø‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶≤‡¶æ‡¶ó‡ßá?",
        "‡¶Ü‡¶Æ‡¶ø ‡¶®‡¶ø‡¶ú‡ßá ‡¶ï‡¶ø ‡¶ö‡¶æ‡¶ï‡¶∞‡¶ø‡¶∞ ‡¶Ü‡¶¨‡ßá‡¶¶‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßã?",
        "‡¶ï‡¶æ‡¶∞‡ßã ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø‡ßá ‡¶ï‡¶ø ‡¶¶‡¶ñ‡¶≤ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶¨‡ßá?",
        "‡¶ú‡¶Æ‡¶ø ‡¶¶‡¶ñ‡¶≤‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶≤‡¶æ‡¶ó‡ßá?",
        "‡¶ú‡¶®‡ßç‡¶Æ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶ï‡¶ø ‡¶¶‡¶∞‡¶ï‡¶æ‡¶∞?",
        "‡¶ú‡¶®‡ßç‡¶Æ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶¶‡¶≤‡¶ø‡¶≤ ‡¶≤‡¶æ‡¶ó‡ßá?",
        "‡¶ú‡¶®‡ßç‡¶Æ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶®‡¶ø‡¶ú‡ßá‡¶∞ ‡¶Æ‡ßã‡¶¨‡¶æ‡¶á‡¶≤ ‡¶•‡¶æ‡¶ï‡¶§‡ßá ‡¶π‡¶¨‡ßá?",
        "‡¶ú‡¶®‡ßç‡¶Æ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶Æ‡ßã‡¶¨‡¶æ‡¶á‡¶≤ ‡¶®‡¶Æ‡ßç‡¶¨‡¶∞ ‡¶õ‡¶æ‡¶°‡¶º‡¶æ ‡¶Ü‡¶∞ ‡¶ï‡¶ø ‡¶≤‡¶æ‡¶ó‡ßá?",
        "‡¶ú‡¶®‡ßç‡¶Æ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶è‡¶®‡¶Ü‡¶á‡¶°‡¶ø ‡¶¨‡¶æ ‡¶ú‡¶®‡ßç‡¶Æ‡¶®‡¶ø‡¶¨‡¶®‡ßç‡¶ß‡¶® ‡¶≤‡¶æ‡¶ó‡ßá ‡¶ï‡¶ø?",
        "‡¶π‡¶ú‡ßç‡¶¨ ‡¶Ü‡¶¨‡ßá‡¶¶‡¶® ‡¶®‡¶ø‡¶ú‡ßá ‡¶®‡¶æ ‡¶ï‡¶∞‡¶≤‡ßá ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶®‡¶ø‡¶ß‡¶ø ‡¶¶‡¶ø‡¶Ø‡¶º‡ßá ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶Ø‡¶º ‡¶ï‡¶ø‡¶®‡¶æ?",
        "‡¶Ü‡¶Æ‡¶ø ‡¶®‡¶ø‡¶ú ‡¶è‡¶≤‡¶æ‡¶ï‡¶æ‡¶∞ ‡¶¨‡¶æ‡¶á‡¶∞‡ßá ‡¶•‡¶æ‡¶ï‡¶ø ‡¶Ö‡¶®‡ßç‡¶Ø ‡¶ï‡ßá‡¶â ‡¶ï‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶®‡¶æ‡¶Æ‡ßá ‡¶ö‡¶æ‡¶Å‡¶¶‡¶æ‡¶¨‡¶æ‡¶ú‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶ï‡¶ø‡¶®‡¶æ?",
        "‡¶Ü‡¶Æ‡¶ø ‡¶¨‡¶ø‡¶¶‡ßá‡¶∂‡ßá ‡¶•‡¶æ‡¶ï‡¶ø ‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶≠‡¶æ‡¶á ‡¶¨‡¶æ ‡¶Ü‡¶§‡ßç‡¶Æ‡ßÄ‡¶Ø‡¶º ‡¶¶‡¶∂ ‡¶™‡¶æ‡¶∞‡¶∏‡ßá‡¶®‡ßç‡¶ü ‡¶Ü‡¶¨‡ßá‡¶¶‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá ‡¶ï‡¶ø‡¶®‡¶æ?",
        "‡¶Ü‡¶Æ‡¶ø ‡¶®‡¶æ‡¶∞‡ßÄ ‡¶ú‡¶Æ‡¶ø‡¶∞ ‡¶ï‡¶ø‡¶õ‡ßÅ‡¶á ‡¶¨‡ßÅ‡¶ù‡¶ø ‡¶®‡¶æ, ‡¶Ü‡¶Æ‡¶ø ‡¶∏‡¶ø‡¶®‡ßá‡¶∏‡¶ø‡¶∏ ‡¶è ‡¶Ü‡¶¨‡ßá‡¶¶‡¶® ‡¶ï‡¶∞‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßã ‡¶§‡ßã?",
    ]
    
    def analyze_model_performance(model, model_name):
        logger.info(f"\n--- {model_name} Performance ---")
        
        # Get embeddings
        namjari_embeddings = model.encode(namjari_queries)
        out_of_scope_embeddings = model.encode(out_of_scope_queries)
        
        # Calculate similarities
        within_namjari_sim = cosine_similarity(namjari_embeddings, namjari_embeddings)
        cross_domain_sim = cosine_similarity(namjari_embeddings, out_of_scope_embeddings)
        
        # Remove diagonal for within-domain
        within_scores = within_namjari_sim[np.triu_indices_from(within_namjari_sim, k=1)]
        
        within_avg = within_scores.mean()
        cross_avg = cross_domain_sim.mean()
        separation = within_avg - cross_avg
        
        # Count problematic cases
        problematic_cases = (cross_domain_sim > 0.6).sum()
        total_cross_pairs = cross_domain_sim.size
        
        logger.info(f"  Within-domain similarity: {within_avg:.3f}")
        logger.info(f"  Cross-domain similarity: {cross_avg:.3f}")
        logger.info(f"  Domain separation: {separation:.3f}")
        logger.info(f"  Problematic cases: {problematic_cases}/{total_cross_pairs} ({problematic_cases/total_cross_pairs*100:.1f}%)")
        
        # Show worst offenders
        worst_cases = []
        for i, namjari_q in enumerate(namjari_queries):
            for j, oos_q in enumerate(out_of_scope_queries):
                sim = cross_domain_sim[i][j]
                if sim > 0.7:  # Very high similarity
                    worst_cases.append((namjari_q, oos_q, sim))
        
        if worst_cases:
            logger.info(f"  üö® Worst cases (similarity > 0.7):")
            for namjari_q, oos_q, sim in sorted(worst_cases, key=lambda x: x[2], reverse=True)[:5]:
                logger.info(f"    {sim:.3f}: '{namjari_q[:30]}...' vs '{oos_q[:30]}...'")
        
        return {
            'within_domain': within_avg,
            'cross_domain': cross_avg,
            'separation': separation,
            'problematic_cases': problematic_cases,
            'total_pairs': total_cross_pairs
        }
    
    # Test both models
    logger.info("Testing model performance...")
    base_results = analyze_model_performance(base_model, "BASE MODEL")
    trained_results = analyze_model_performance(trained_model, "TRAINED MODEL")
    
    # Quick sanity check with realistic examples
    logger.info(f"\n--- Quick Sanity Check ---")
    
    test_cases = [
        # Should be similar (same concept)
        ("‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?", "‡¶≠‡ßÇ‡¶Æ‡¶ø ‡¶∞‡ßá‡¶ï‡¶∞‡ßç‡¶° ‡¶™‡¶∞‡¶ø‡¶¨‡¶∞‡ßç‡¶§‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶≤‡¶æ‡¶ó‡ßá?"),
        
        # Should be moderately similar (related legal concepts)  
        ("‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø‡¶∞ ‡¶´‡¶ø ‡¶ï‡¶§?", "‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶¶‡¶≤‡¶ø‡¶≤ ‡¶≤‡¶æ‡¶ó‡ßá?"),
        
        # Should be low similarity (unrelated)
        ("‡¶®‡¶æ‡¶Æ‡¶ú‡¶æ‡¶∞‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶ï‡¶ø ‡¶ï‡¶∞‡¶§‡ßá ‡¶π‡¶¨‡ßá?", "‡¶Ü‡¶ú‡¶ï‡ßá‡¶∞ ‡¶Ü‡¶¨‡¶π‡¶æ‡¶ì‡¶Ø‡¶º‡¶æ ‡¶ï‡ßá‡¶Æ‡¶®?"),
    ]
    
    for i, (q1, q2) in enumerate(test_cases):
        emb1 = trained_model.encode([q1])
        emb2 = trained_model.encode([q2])
        sim = cosine_similarity(emb1, emb2)[0][0]
        
        logger.info(f"  Test {i+1}: {sim:.3f}")
        logger.info(f"    Q1: {q1}")
        logger.info(f"    Q2: {q2}")
    
    return trained_results, base_results

if __name__ == "__main__":
    try:
        trained_results, base_results = test_final_model()
        
        if trained_results and base_results:
            print("\n" + "="*80)
            print("üéØ FINAL MODEL TEST RESULTS")
            print("="*80)
            print("üìä Trained Model Performance:")
            print(f"   Within-domain similarity: {trained_results['within_domain']:.3f}")
            print(f"   Cross-domain similarity: {trained_results['cross_domain']:.3f}")
            print(f"   Domain separation: {trained_results['separation']:.3f}")
            print(f"   Problematic cases: {trained_results['problematic_cases']}/{trained_results['total_pairs']}")
            
            improvement = ((base_results['cross_domain'] - trained_results['cross_domain']) / base_results['cross_domain']) * 100
            print(f"   Improvement vs base: {improvement:.1f}%")
            
            print("\nüîç Key Findings:")
            if trained_results['separation'] > 0.2:
                print("   ‚úÖ Reasonable domain separation achieved")
            else:
                print("   ‚ö†Ô∏è Weak domain separation (Bengali syntactic challenge)")
                
            if trained_results['problematic_cases'] < 20:
                print("   ‚úÖ Few problematic out-of-scope cases")
            else:
                print("   ‚ö†Ô∏è Many problematic out-of-scope cases (expected for Bengali)")
            
            print(f"\nüìù See FINDINGS.md for detailed analysis and alternative approaches")
            print("="*80)
            
    except Exception as e:
        logger.error(f"Final test failed: {e}")
        raise
